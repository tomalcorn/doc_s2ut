no_progress_bar	False
log_interval	100
log_format	None
log_file	None
aim_repo	None
aim_run_hash	None
tensorboard_logdir	None
wandb_project	None
azureml_logging	False
seed	1
cpu	False
tpu	False
bf16	False
memory_efficient_bf16	False
fp16	False
memory_efficient_fp16	False
fp16_no_flatten_grads	False
fp16_init_scale	128
fp16_scale_window	None
fp16_scale_tolerance	0.0
on_cpu_convert_precision	False
min_loss_scale	0.0001
threshold_loss_scale	None
amp	False
amp_batch_retries	2
amp_init_scale	128
amp_scale_window	None
user_dir	None
empty_cache_freq	0
all_gather_list_size	16384
model_parallel_size	1
quantization_config_path	None
profile	False
reset_logging	False
suppress_crashes	False
use_plasma_view	False
plasma_path	/tmp/plasma
criterion	speech_to_unit
tokenizer	None
bpe	None
optimizer	adam
lr_scheduler	inverse_sqrt
simul_type	None
scoring	bleu
task	speech_to_speech
num_workers	8
skip_invalid_size_inputs_valid_test	False
max_tokens	20000
batch_size	None
required_batch_size_multiple	8
required_seq_len_multiple	1
dataset_impl	None
data_buffer_size	10
train_subset	train
valid_subset	dev
combine_valid_subsets	None
ignore_unused_valid_subsets	False
validate_interval	1
validate_interval_updates	0
validate_after_updates	0
fixed_validation_seed	None
disable_validation	False
max_tokens_valid	20000
batch_size_valid	None
max_valid_steps	None
curriculum	0
gen_subset	test
num_shards	1
shard_id	0
grouped_shuffling	False
update_epoch_batch_itr	False
update_ordered_indices_seed	False
distributed_world_size	1
distributed_num_procs	1
distributed_rank	0
distributed_backend	nccl
distributed_init_method	None
distributed_port	-1
device_id	0
distributed_no_spawn	False
ddp_backend	pytorch_ddp
ddp_comm_hook	none
bucket_cap_mb	25
fix_batches_to_gpus	False
find_unused_parameters	False
gradient_as_bucket_view	False
fast_stat_sync	False
heartbeat_timeout	-1
broadcast_buffers	False
slowmo_momentum	None
slowmo_base_algorithm	localsgd
localsgd_frequency	3
nprocs_per_node	1
pipeline_model_parallel	False
pipeline_balance	None
pipeline_devices	None
pipeline_chunks	0
pipeline_encoder_balance	None
pipeline_encoder_devices	None
pipeline_decoder_balance	None
pipeline_decoder_devices	None
pipeline_checkpoint	never
zero_sharding	none
no_reshard_after_forward	False
fp32_reduce_scatter	False
cpu_offload	False
use_sharded_state	False
not_fsdp_flatten_parameters	False
arch	s2ut_transformer_afs
max_epoch	400
max_update	400000
stop_time_hours	0
clip_norm	10.0
sentence_avg	False
update_freq	[1]
lr	[0.0005]
stop_min_lr	-1.0
use_bmuf	False
skip_remainder_batch	False
debug_param_names	False
save_dir	/Users/tomalcorn/Documents/University/pg/diss/mine/models
restore_file	checkpoint_last.pt
continue_once	None
finetune_from_model	None
reset_dataloader	False
reset_lr_scheduler	False
reset_meters	False
reset_optimizer	False
optimizer_overrides	{}
save_interval	10
save_interval_updates	0
keep_interval_updates	-1
keep_interval_updates_pattern	-1
keep_last_epochs	-1
keep_best_checkpoints	-1
no_save	False
no_epoch_checkpoints	False
no_last_checkpoints	False
no_save_optimizer_state	False
best_checkpoint_metric	loss
maximize_best_checkpoint_metric	False
patience	-1
checkpoint_suffix
checkpoint_shard_count	1
load_checkpoint_on_all_dp_ranks	False
write_checkpoints_asynchronously	False
store_ema	False
ema_decay	0.9999
ema_start_update	0
ema_seed_model	None
ema_update_freq	1
ema_fp32	False
conv_version	afs
feat_extractor_pretraining_path	/Users/tomalcorn/Documents/University/pg/diss/7_AFS/ASR_AFS_SAVE_BIG/checkpoint_best.pt
feat_extractor_args	/Users/tomalcorn/Documents/University/pg/diss/7_AFS/feat_extractor_args.tsv
activation_fn	relu
data	/Users/tomalcorn/Documents/University/pg/diss/DATA_ROOT
config_yaml	config.yaml
multitask_config_yaml	config_multitask.yaml
max_source_positions	6000
max_target_positions	3000
target_is_code	True
target_code_size	100
n_frames_per_step	1
eval_inference	False
eval_args	{}
eos_prob_threshold	0.5
mcd_normalize_type	targ
vocoder	code_hifigan
spec_bwd_max_iter	8
infer_target_lang
label_smoothing	0.2
report_accuracy	False
ignore_prefix_size	0
rdrop_alpha	0.0
adam_betas	(0.9,0.98)
adam_eps	1e-08
weight_decay	0.0
use_old_adam	False
fp16_adam_stats	False
warmup_updates	10000
warmup_init_lr	1e-07
pad	1
eos	2
unk	3
share_decoder_input_output_embed	True
dropout	0.1
attention_dropout	0.1
activation_dropout	0.1
no_seed_provided	False
encoder_embed_dim	256
encoder_attention_heads	4
encoder_freezing_updates	0
input_channels	1
conv_kernel_sizes	5,5
conv_channels	1024
conv_out_channels	256
encoder_ffn_embed_dim	2048
encoder_layers	12
encoder_normalize_before	True
no_scale_embedding	False
speaker_embed_dim	256
decoder_embed_dim	256
decoder_ffn_embed_dim	2048
decoder_layers	6
decoder_attention_heads	8
decoder_normalize_before	True
decoder_learned_pos	False
adaptive_softmax_cutoff	None
adaptive_softmax_dropout	0
no_token_positional_embeddings	False
adaptive_input	False
decoder_layerdrop	0.0
decoder_output_dim	256
decoder_input_dim	256
quant_noise_pq	0
_name	s2ut_transformer_afs
input_feat_per_channel	80
target_speaker_embed	False